{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data-driven Simulation: Fill Chameleon Resource Usage Gaps Using HTC Workloads\n",
    "\n",
    "This is the experiment entrace for the SC2021 SRC poster: Yin and Yang: Balancing Cloud Computing and HTC Workloads.\n",
    "\n",
    "The code repository is available at: https://github.com/VUZhuangweiKang/CHISim\n",
    "\n",
    "CHISim is a data-driven simulator developed for evaluating the strategies of co-locating Chameleon Cloud with High Throughput Computing(HTC) workloads. CHISim replicates the components and processing logic of the OpenStack Blazar, the Chameleon resource manager. This Jupyter Notebook illustrates how to set up the experimental environment (create and configure a bare-metal instance using the Blazar API and Ansible scripts) for the CHISim simulator and run experiments.\n",
    "\n",
    "The below figure shows the main workflow of CHISim. In the below experiment, CHISim takes Chameleon [trace data](https://www.scienceclouds.org/cloud-traces) (March 2018 to May 2020) and HTC workloads(replay a 3-day OSG log file) as inputs. \n",
    "\n",
    "<img src=\"../images/arch.png\" width=\"600\">\n",
    "\n",
    "The Request Forecaster estimates Chameleon on-demand requests with the below strategies:\n",
    "- Baseline: run Chameleon user requests only(no advance notice for preemption);\n",
    "- Greedy algorithm: filling lease gaps with HTC jobs on all available resources(no advance notice for preemption);\n",
    "- Predictive filling: use forecasters and preemption policies (conducted 12 experiments with 4 preemption policies and 3 prediction models).\n",
    "    \n",
    "The Resource Manager involves four preemption policies as below:\n",
    "- Random: preempt nodes from the HTC pool arbitrarily;\n",
    "- Recent-Deployed: preempt nodes that are assigned to HTC most recently;\n",
    "- Least-Core-Used: preempt nodes with the least number of cores assigned to HTC jobs;\n",
    "- Least-Resubmit: preempt nodes with the least number of re-submissions.\n",
    "\n",
    "Three experiments were conducted in the \n",
    "__Requirements:__ This experiment was packaged to run on the [Chameleon testbed](https://www.chameleoncloud.org), using Jupyter Notebook. To run this, you'll need a Chameleon account and an active project allocation. \n",
    "\n",
    "__Estimated Time:__ depends on the number of configurations(preemption policy * request forecasting algorithm) you want to evaluate.\n",
    "\n",
    "\n",
    "__Steps:__     \n",
    "1. __Create a Chameleon Lease and Launch an Bare-metal Instance:__      \n",
    "    a. Obtain a lease using Blazar API    \n",
    "    b. Create a stack of openstack services based on template: _chameleon/jupyterhub_heat_template.yml_    \n",
    "    c. Install and configure Ansible and JupyterHub   \n",
    "2. __Prepare and Run Experiment:__\n",
    "    a. Install depedent packages for CHISim: ansible/chisim-setup.yml\n",
    "    b. Define the experiment profile: [config](exp-config.yaml)\n",
    "    c. Start experiments using SSH, experiment logs are in: logs/xxx.log\n",
    "3. __Visualize Experiment Process:__   \n",
    "    a. Create Grafana dashboard: ansible/chisim-visual.yml  \n",
    "    b. Visualize the experimental metrics: http://$fip_addr:3000\n",
    "\n",
    "__Contact:__ \n",
    "[Zhuangwei Kang](zhuangwei.kang@vanderbilt.edu)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1. Create a Chameleon Lease and Launch a Bare-metal Instance\n",
    "\n",
    "Please replace the values of use_site and OS_PROJECT_NAME with yours. The suggested runtime environment for CHISim is a ComputeHaswell node  with the Ubuntu 20.04 OS."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "use_site \"the Chameleon site you are using\" # for example: \"CHI@TACC\"\n",
    "export OS_PROJECT_NAME=\"your project name\"  # e.g. \"CHI-000000\"\n",
    "\n",
    "NODE_TYPE=compute_haswell\n",
    "IMAGE=CC-Ubuntu20.04\n",
    "EMAIL=\"$(openstack user show $USER -f value -c email)\"\n",
    "\n",
    "# A unique name for most provisioned resources to avoid collisions\n",
    "RESOURCE_NAME=\"${USER}-jupyterhub-$(date +%b%d)\"\n",
    "\n",
    "[[ -n \"$EMAIL\" ]] || {\n",
    "  echo >&2 \"Could not look up your user, check your OS_PROJECT_NAME\"\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Obtain a lease using Blazar API    \n",
    "\n",
    "Execute commands in the below cell and wait until you can see an ACTIVE lease on the page: https://chi.tacc.chameleoncloud.org/project/leases/."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lease_name=\"$RESOURCE_NAME\"\n",
    "network_name=\"$RESOURCE_NAME\"\n",
    "public_network_id=$(openstack network show public -f value -c id)\n",
    "\n",
    "blazar lease-create \\\n",
    "  --physical-reservation min=1,max=1,resource_properties=\"[\\\"=\\\", \\\"\\$node_type\\\", \\\"$NODE_TYPE\\\"]\" \\\n",
    "  --reservation resource_type=network,network_name=\"$network_name\",resource_properties='[\"==\",\"$physical_network\",\"physnet1\"]' \\\n",
    "  --reservation resource_type=virtual:floatingip,network_id=\"$public_network_id\",amount=1 \\\n",
    "  --start-date \"$(date +'%Y-%m-%d %H:%M')\" \\\n",
    "  --end-date \"$(date +'%Y-%m-%d %H:%M' -d'+2 day')\" \\\n",
    "  \"$lease_name\"\n",
    "\n",
    "# Wait for lease to start\n",
    "timeout 30000 bash -c 'until [[ $(blazar lease-show $0 -f value -c status) == \"ACTIVE\" ]]; do sleep 1; done' \"$lease_name\" \\\n",
    "    && echo \"Lease started successfully!\"\n",
    "\n",
    "#\n",
    "# Fetch information about which resources were reserved for later use\n",
    "#\n",
    "\n",
    "reservations=$(blazar lease-show \"$lease_name\" -f json \\\n",
    "  | jq -r '.reservations')\n",
    "host_reservation_id=$(jq -rs 'map(select(.resource_type==\"physical:host\"))[].id' <<<\"$reservations\")\n",
    "fip_reservation_id=$(jq -rs 'map(select(.resource_type==\"virtual:floatingip\"))[].id' <<<\"$reservations\")\n",
    "\n",
    "fip=$(openstack floating ip list --tags \"reservation:$fip_reservation_id\" -f json)\n",
    "fip_id=$(jq -r 'map(.ID)[0]' <<<\"$fip\")\n",
    "fip_addr=$(jq -r 'map(.[\"Floating IP Address\"])[0]' <<<\"$fip\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Create a stack of openstack services\n",
    "\n",
    "The below create a stack of OpenStack services based on a set of input settings and a template file. More details about OpenStack Orchestration can be found [here](https://docs.openstack.org/mitaka/user-guide/dashboard_stacks.html). \n",
    "\n",
    "The stack status is trackable [here](https://chi.tacc.chameleoncloud.org/project/stacks/).\n",
    "\n",
    "This step usually takes about 20 minutes. The instance status will become ACTIVE if the creation is successful. To check the instance status, please see: https://chi.tacc.chameleoncloud.org/project/instances/."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Ensure your Jupyter keypair is present\n",
    "key_pair_upload"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stack_name=\"$RESOURCE_NAME\"\n",
    "export OS_KEYPAIR_NAME=\"your account name-jupyter\"\n",
    "\n",
    "openstack stack create \"$stack_name\" --wait \\\n",
    "  --template chameleon/jupyterhub_heat_template.yml \\\n",
    "  --parameter floating_ip=\"$fip_id\" \\\n",
    "  --parameter reservation_id=\"$host_reservation_id\" \\\n",
    "  --parameter key_name=\"$OS_KEYPAIR_NAME\" \\\n",
    "  --parameter network_name=\"$network_name\" \\\n",
    "  --parameter image=\"$IMAGE\" && wait_ssh \"$fip_addr\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Install and configure Ansible and JupyterHub\n",
    "\n",
    "The underlying base image does not have JupyterHub OS_KEYPAIR_NAME installed. To install and configure it, this example uses [Ansible](https://www.ansible.com/). First, some configuration of Ansible is required:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Install Ansible dependencies\n",
    "ansible-galaxy install -r ansible/requirements.yml\n",
    "\n",
    "# Configure Ansible to run against provisioned nodes\n",
    "sudo mkdir -p /etc/ansible\n",
    "sudo tee /etc/ansible/hosts <<EOF\n",
    "[jupyterhub]\n",
    "$fip_addr ansible_user=cc ansible_become=yes ansible_become_user=root\n",
    "EOF"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export ANSIBLE_HOST_KEY_CHECKING=False\n",
    "ansible-playbook --extra floating_ip=\"$fip_addr\" --extra email_address=\"$EMAIL\" ansible/bootstrap.yml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ansible-playbook ansible/configure.yml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2. Prepare and Run Experiment\n",
    "\n",
    "### 2.1 Install depedent packages of CHISim\n",
    "\n",
    "This step downloads CHISim git repositpory on the remote node you just created. Then it installs and configures serveral fundamental components: influxdb, rabbitmq and mongodb."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ansible-playbook ansible/chisim-setup.yml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Configure Experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use a [YAML file](exp-config.yaml) to define the experiment profile in CHISim. The below shows the meaning of each field. \n",
    "\n",
    "The input temporal data files include:\n",
    "- [cloud user requests](https://github.com/VUZhuangweiKang/CHISim/blob/main/simulator/datasets/user_requests/compute_haswell.csv)\n",
    "- [machine events](https://github.com/VUZhuangweiKang/CHISim/blob/main/simulator/datasets/machine_events/compute_haswell.csv)\n",
    "- [osg jobs](https://github.com/VUZhuangweiKang/CHISim/blob/main/simulator/datasets/osg_jobs/osg_jobs.csv)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```yaml\n",
    "---\n",
    "simulation:\n",
    "  termination_policy: random  # Options: ['random', 'least_core', 'least_resubmit', 'recent_deployed']\n",
    "  request_predictor: baseline  # Options: ['baseline', 'rolling_mean', 'rolling_median', 'lstm']\n",
    "  scale_ratio: 10800  # the ratio of scaling in the timestamp of input time-series data\n",
    "  credential:  # username and password for influxdb, mongodb, and rabbitmq connections\n",
    "    username: chi-sim\n",
    "    password: chi-sim\n",
    "  enable_osg: yes  # whether to enable osg jobs, this should be set to no in the Baseline experiment\n",
    "\n",
    "framework:\n",
    "  global_mgr:\n",
    "    clean_run: yes  # whether to clear the old rabbitmq queues and exchanges.\n",
    "  rsrc_mgr:\n",
    "    host: localhost\n",
    "  frontend:\n",
    "    request_forecaster:\n",
    "      window: 168  # the length of the sliding window in hours\n",
    "      steps: 3  # the length of the current time slot in hours; for example, 3 means the Forecaster predicts the total cloud user requests in the upcoming 3 hours.\n",
    "      retrain:\n",
    "        enabled: yes  # whether to retain the LSTM model periodically, this is only usable for the LSTM-based Forecaster\n",
    "        length: 30000   # the period(# of samples) of retraining LSTM models\n",
    "  databus:\n",
    "    rabbitmq: 127.0.0.1\n",
    "  database:\n",
    "    influxdb: 127.0.0.1\n",
    "    mongodb: 127.0.0.1\n",
    "\n",
    "workloads:  # the workload entry is composed of the path of the data file and the index of the temporal column.\n",
    "  machine_events:\n",
    "    payload: ../datasets/machine_events/compute_haswell.csv\n",
    "    timestamp_col: 0\n",
    "  osg_jobs:\n",
    "    payload: datasets/osg_jobs/osg_jobs.csv\n",
    "    timestamp_col: 13\n",
    "  chameleon_requests:\n",
    "    payload: datasets/user_requests/lease_info.csv\n",
    "    timestamp_col: -1\n",
    " ```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# copy the experiment profile to the remote machine\n",
    "ansible-playbook ansible/chisim-config.yml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Start Experiments\n",
    "\n",
    "Launch components of CHISim running on the remote machine through SSH and redirect execution log files to the [logs](./logs) directory. Each component runs as an independent process and the process id is saved in [pid.text](pid.txt)."
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nohup bash -c \"ssh -i ~/work/.ssh/id_rsa cc@$fip_addr \\\"cd /home/cc/CHISim/simulator/ && python3 global_manager.py\\\"\" > logs/global_manager.log & echo $!>> pid.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nohup bash -c \"ssh -i ~/work/.ssh/id_rsa cc@$fip_addr \\\"cd /home/cc/CHISim/simulator/ && python3 resource_manager.py\\\"\" > logs/resource_manager.log & echo $!>> pid.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nohup bash -c \"ssh -i ~/work/.ssh/id_rsa cc@$fip_addr \\\"cd /home/cc/CHISim/simulator/ && python3 frontend.py\\\"\" > logs/frontend.log & echo $!>> pid.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nohup bash -c \"ssh -i ~/work/.ssh/id_rsa cc@$fip_addr \\\"cd /home/cc/CHISim/simulator/ && python3 backfill.py\\\"\" > logs/backfill.log & echo $!>> pid.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nohup bash -c \"ssh -i ~/work/.ssh/id_rsa cc@$fip_addr \\\"cd /home/cc/CHISim/simulator/ && python3 workload.py\\\"\" > logs/workload.log & echo $!>> pid.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3. Visualize Experiment Process\n",
    "\n",
    "### 3.1 Install Grafana and customize the dashboard\n",
    "\n",
    "The dashboard is defined as a [json file](ansible/chisim-deploy/grafana-dashboard.json)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ansible-playbook --extra floating_ip=\"$fip_addr\" ansible/chisim-visual.yml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Monitor the experiment\n",
    "echo \"Grafana: http://$fip_addr:3000\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4. Shutdown Experiments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kill -9 $(cat pid.txt)\n",
    "rm pid.txt\n",
    "ansible-playbook ansible/chisim-shutdown.yml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After the execution, you can easily export measured metrics as CSV files through the Grafana dashboard. Since the data source of Grafana is InfluxDB, an alternative way of extracting data is querying InfluxDB directly."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}